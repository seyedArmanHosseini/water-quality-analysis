{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RdQqTzc4infW"
      },
      "outputs": [],
      "source": [
        "# Importing all the necessary libraries for data processing, visualization, modeling, and evaluation\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Visualization\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Preprocessing\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Modeling\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor, plot_importance\n",
        "\n",
        "# Evaluation\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Utilities\n",
        "import joblib\n",
        "import time\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Load Dataset from a Specified Path\n",
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data = pd.read_csv('/kaggle/input/water-quality-index-wqi/Results_MADE.csv')\n",
        "\n",
        "print(\"Displaying first 5 rows of the dataset:\")\n",
        "display(data.head())\n",
        "\n",
        "print(\"\\nDataset Information:\")\n",
        "print(data.info())\n",
        "\n",
        "print(\"\\nDescriptive Statistics:\")\n",
        "display(data.describe())\n",
        "\n",
        "print(\"\\nMissing Values Count per Column:\")\n",
        "print(data.isnull().sum())\n",
        "\n",
        "# ==============================================\n",
        "# 2. Handling Missing Values\n",
        "# ==============================================\n",
        "\n",
        "print(\"\\nFilling missing values with column mean...\")\n",
        "\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "data_imputed = pd.DataFrame(imputer.fit_transform(data), columns=data.columns)\n",
        "\n",
        "# ==============================================\n",
        "# 3. Removing Outliers\n",
        "# ==============================================\n",
        "\n",
        "def remove_outliers(df, column):\n",
        "    Q1 = df[column].quantile(0.25)\n",
        "    Q3 = df[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower = Q1 - 1.5 * IQR\n",
        "    upper = Q3 + 1.5 * IQR\n",
        "    return df[(df[column] >= lower) & (df[column] <= upper)]\n",
        "\n",
        "print(\"\\nRemoving outliers from numerical columns...\")\n",
        "\n",
        "num_cols = data_imputed.select_dtypes(include=['float64', 'int64']).columns\n",
        "before_len = len(data_imputed)\n",
        "\n",
        "for col in num_cols:\n",
        "    data_imputed = remove_outliers(data_imputed, col)\n",
        "\n",
        "after_len = len(data_imputed)\n",
        "print(f\"Records before: {before_len} / after: {after_len}\")\n",
        "\n",
        "# ==============================================\n",
        "# 4. Normalizing Features\n",
        "# ==============================================\n",
        "\n",
        "print(\"\\nNormalizing features using StandardScaler...\")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "data_scaled = pd.DataFrame(scaler.fit_transform(data_imputed), columns=data_imputed.columns)\n",
        "\n",
        "# ==============================================\n",
        "# 5. Splitting Features and Target (WQI)\n",
        "# ==============================================\n",
        "\n",
        "X = data_scaled.drop('WQI', axis=1)\n",
        "y = data_scaled['WQI']\n",
        "\n",
        "# ==============================================\n",
        "# 6. Train-Test Split\n",
        "# ==============================================\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"\\nData is ready for modeling:\")\n",
        "print(f\"Train samples: {X_train.shape[0]}\")\n",
        "print(f\"Test samples : {X_test.shape[0]}\")\n"
      ],
      "metadata": {
        "id": "QaeVJ4BEiuAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# 1. Load the dataset\n",
        "# ==============================\n",
        "data = pd.read_csv('/kaggle/input/water-quality-index-wqi/Results_MADE.csv')  # Change path accordingly\n",
        "\n",
        "# ==============================\n",
        "# 2. Handle missing values\n",
        "# ==============================\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "data_imputed = pd.DataFrame(imputer.fit_transform(data), columns=data.columns)\n",
        "\n",
        "# ==============================\n",
        "# 3. Remove outliers\n",
        "# ==============================\n",
        "def remove_outliers(df, column):\n",
        "    Q1 = df[column].quantile(0.25)\n",
        "    Q3 = df[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
        "\n",
        "numeric_columns = data_imputed.select_dtypes(include=['float64', 'int64']).columns\n",
        "for col in numeric_columns:\n",
        "    data_imputed = remove_outliers(data_imputed, col)\n",
        "\n",
        "# ==============================\n",
        "# 4. Standardize the features\n",
        "# ==============================\n",
        "scaler = StandardScaler()\n",
        "data_scaled = pd.DataFrame(scaler.fit_transform(data_imputed), columns=data_imputed.columns)\n",
        "\n",
        "# ==============================\n",
        "# 5. Feature/target split\n",
        "# ==============================\n",
        "X = data_scaled.drop('WQI', axis=1)\n",
        "y = data_scaled['WQI']\n",
        "\n",
        "# Split into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# ==============================\n",
        "# 6. Train Linear Regression Model\n",
        "# ==============================\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# ==============================\n",
        "# 7. Predictions and Evaluation\n",
        "# ==============================\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"=== Linear Regression Model Evaluation ===\")\n",
        "print(f\"MAE:  {mae:.4f}\")\n",
        "print(f\"RMSE: {rmse:.4f}\")\n",
        "print(f\"R²:   {r2:.4f}\")\n",
        "\n",
        "# ==============================\n",
        "# 8. Actual vs Predicted Plot\n",
        "# ==============================\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.scatterplot(x=y_test, y=y_pred, alpha=0.7)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
        "plt.xlabel(\"Actual WQI\")\n",
        "plt.ylabel(\"Predicted WQI\")\n",
        "plt.title(\"Actual vs Predicted WQI\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ==============================\n",
        "# 9. Coefficients Overview\n",
        "# ==============================\n",
        "coefficients = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Coefficient': model.coef_\n",
        "}).sort_values(by='Coefficient', ascending=False)\n",
        "\n",
        "print(\"\\n=== Linear Regression Coefficients ===\")\n",
        "print(coefficients)\n",
        "\n",
        "# ==============================\n",
        "# 10. Residuals Distribution\n",
        "# ==============================\n",
        "residuals = y_test - y_pred\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.histplot(residuals, kde=True, bins=20)\n",
        "plt.xlabel(\"Residuals\")\n",
        "plt.title(\"Distribution of Residuals\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ==============================\n",
        "# 11. Cross-Validation\n",
        "# ==============================\n",
        "cv_scores = cross_val_score(model, X, y, cv=5, scoring='r2')\n",
        "print(f\"\\nCross-Validated R² Score: {np.mean(cv_scores):.4f} (±{np.std(cv_scores):.4f})\")\n"
      ],
      "metadata": {
        "id": "qUmUvujDiwwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# 1. Train Random Forest Regressor\n",
        "# ==============================\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# ==============================\n",
        "# 2. Predictions and Evaluation\n",
        "# ==============================\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "\n",
        "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
        "rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
        "r2_rf = r2_score(y_test, y_pred_rf)\n",
        "\n",
        "print(\"\\n=== Random Forest Regression Performance ===\")\n",
        "print(f\"MAE :  {mae_rf:.4f}\")\n",
        "print(f\"RMSE:  {rmse_rf:.4f}\")\n",
        "print(f\"R²   :  {r2_rf:.4f}\")\n",
        "\n",
        "# ==============================\n",
        "# 3. Cross-Validation\n",
        "# ==============================\n",
        "cv_scores_rf = cross_val_score(rf_model, X, y, cv=5, scoring='r2')\n",
        "print(f\"\\nCross-Validated R² Score: {np.mean(cv_scores_rf):.4f} (±{np.std(cv_scores_rf):.4f})\")\n",
        "\n",
        "# ==============================\n",
        "# 4. Feature Importance\n",
        "# ==============================\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Importance': rf_model.feature_importances_\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "print(\"\\n=== Feature Importances ===\")\n",
        "print(importance_df)\n",
        "\n",
        "# ==============================\n",
        "# 5. Plot Feature Importance\n",
        "# ==============================\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Importance', y='Feature', data=importance_df, palette='viridis')\n",
        "plt.title('Feature Importance - Random Forest Regressor', fontsize=14)\n",
        "plt.xlabel('Relative Importance', fontsize=12)\n",
        "plt.ylabel('Feature', fontsize=12)\n",
        "plt.grid(axis='x', linestyle='--', alpha=0.6)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "aAbXX8JPi0LR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using only Conductivity column as feature and WQI as target\n",
        "X_single = data_scaled[['Conductivity (mho/ Cm)']]\n",
        "y_single = data_scaled['WQI']\n",
        "\n",
        "# Split into Train and Test sets\n",
        "X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(X_single, y_single, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define model\n",
        "rf_single = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_single.fit(X_train_s, y_train_s)\n",
        "\n",
        "# Prediction and evaluation\n",
        "y_pred_s = rf_single.predict(X_test_s)\n",
        "mae_s = mean_absolute_error(y_test_s, y_pred_s)\n",
        "rmse_s = np.sqrt(mean_squared_error(y_test_s, y_pred_s))\n",
        "r2_s = r2_score(y_test_s, y_pred_s)\n",
        "\n",
        "print(\"\\n\\033[1;33m=== Random Forest Evaluation (Conductivity only) ===\\033[0m\")\n",
        "print(f\"MAE:  {mae_s:.4f}\")\n",
        "print(f\"RMSE: {rmse_s:.4f}\")\n",
        "print(f\"R2:   {r2_s:.4f}\")\n",
        "\n",
        "# Cross-validation\n",
        "cv_scores_s = cross_val_score(rf_single, X_single, y_single, cv=5, scoring='r2')\n",
        "print(f\"\\nR2-Score with Cross-Validation: {np.mean(cv_scores_s):.4f} (±{np.std(cv_scores_s):.4f})\")"
      ],
      "metadata": {
        "id": "KiSdms2ti2Yg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Defining the model with optimal parameters\n",
        "xgb_model = XGBRegressor(\n",
        "    n_estimators=150,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=5,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    random_state=42,\n",
        "    eval_metric='mae'\n",
        ")\n",
        "\n",
        "# 2. Training the model\n",
        "xgb_model.fit(\n",
        "    X_train, y_train,\n",
        "    eval_set=[(X_test, y_test)],\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# 3. Predictions\n",
        "y_pred_xgb = xgb_model.predict(X_test)\n",
        "\n",
        "# 4. Calculating metrics\n",
        "metrics = {\n",
        "    'MAE': mean_absolute_error(y_test, y_pred_xgb),\n",
        "    'RMSE': np.sqrt(mean_squared_error(y_test, y_pred_xgb)),\n",
        "    'R2': r2_score(y_test, y_pred_xgb),\n",
        "    'MAPE': np.mean(np.abs((y_test - y_pred_xgb) / np.where(y_test==0, 1, y_test))) * 100\n",
        "}\n",
        "\n",
        "# 5. Displaying the results\n",
        "print(\"\\n\" + \"=\"*40)\n",
        "print(\" Final Evaluation of XGBoost Model\")\n",
        "print(\"=\"*40)\n",
        "for name, value in metrics.items():\n",
        "    print(f\"{name}: {value:.4f}\")\n",
        "\n",
        "# 6. Saving the model\n",
        "joblib.dump(xgb_model, 'xgb_wqi_model.pkl')\n",
        "\n",
        "# 7. Feature importance plot\n",
        "plt.figure(figsize=(10,6))\n",
        "plot_importance(xgb_model, max_num_features=10, importance_type='weight')\n",
        "plt.title('Feature Importance in XGBoost Model')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "AlMYvLF5i45Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Defining the model\n",
        "rf_model = RandomForestRegressor(random_state=42)\n",
        "\n",
        "# 2. Optimized hyperparameters\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'max_features': ['sqrt', 'log2']\n",
        "}\n",
        "\n",
        "# 3. Setting up GridSearchCV\n",
        "grid_search_rf = GridSearchCV(\n",
        "    estimator=rf_model,\n",
        "    param_grid=param_grid_rf,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    cv=5,\n",
        "    n_jobs=-1,  # Using all CPU cores\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# 4. Running the hyperparameter search\n",
        "print(\"Starting hyperparameter tuning...\")\n",
        "start_time = time.time()\n",
        "grid_search_rf.fit(X_train, y_train)\n",
        "print(f\"Execution time: {(time.time() - start_time)/60:.2f} minutes\")\n",
        "\n",
        "# 5. Results\n",
        "print(\"\\nBest parameters:\")\n",
        "print(grid_search_rf.best_params_)\n",
        "\n",
        "print(\"\\nBest score (MSE):\")\n",
        "print(f\"{grid_search_rf.best_score_:.4f}\")\n",
        "\n",
        "# 6. Saving the best model\n",
        "best_rf = grid_search_rf.best_estimator_\n"
      ],
      "metadata": {
        "id": "D49Ym8ili7ZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# 1. Define base XGBoost model\n",
        "xgb_model = XGBRegressor(\n",
        "    random_state=42,\n",
        "    objective='reg:squarederror',\n",
        "    n_jobs=-1,\n",
        "    verbosity=0  # Suppress internal XGBoost messages\n",
        ")\n",
        "\n",
        "# 2. Define parameter grid for hyperparameter tuning\n",
        "param_grid_xgb = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'subsample': [0.6, 0.8, 1.0],\n",
        "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
        "    'gamma': [0, 0.1, 0.2]\n",
        "}\n",
        "\n",
        "# 3. Setup advanced GridSearchCV with multiple scoring metrics\n",
        "grid_search_xgb = GridSearchCV(\n",
        "    estimator=xgb_model,\n",
        "    param_grid=param_grid_xgb,\n",
        "    scoring={\n",
        "        'MAE': 'neg_mean_absolute_error',\n",
        "        'MSE': 'neg_mean_squared_error',\n",
        "        'R2': 'r2'\n",
        "    },\n",
        "    refit='MSE',  # Select best model based on MSE\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        "    verbose=0  # Suppress cross-validation output\n",
        ")\n",
        "\n",
        "# 4. Run the search with time tracking\n",
        "print(\" Starting hyperparameter optimization...\")\n",
        "start_time = time.time()\n",
        "grid_search_xgb.fit(X_train, y_train)\n",
        "elapsed_time = (time.time() - start_time) / 60\n",
        "print(f\" Optimization completed in {elapsed_time:.2f} minutes.\")\n",
        "\n",
        "# 5. Show the final results\n",
        "print(\"\\n🎯 Best Hyperparameters:\")\n",
        "print(grid_search_xgb.best_params_)\n",
        "\n",
        "# Extract best index and performance metrics\n",
        "best_index = grid_search_xgb.best_index_\n",
        "results = pd.DataFrame(grid_search_xgb.cv_results_)\n",
        "\n",
        "print(\"\\n Best Model Evaluation Metrics:\")\n",
        "print(results.loc[best_index, [\n",
        "    'mean_test_MAE',\n",
        "    'mean_test_MSE',\n",
        "    'mean_test_R2'\n",
        "]].rename({\n",
        "    'mean_test_MAE': 'MAE',\n",
        "    'mean_test_MSE': 'MSE',\n",
        "    'mean_test_R2': 'R²'\n",
        "}).to_string())\n",
        "\n",
        "# 6. Save the best model to file\n",
        "best_xgb = grid_search_xgb.best_estimator_\n",
        "best_xgb.save_model('best_xgb_model.json')\n",
        "\n",
        "# 7. Analyze feature importance\n",
        "importance = best_xgb.get_booster().get_score(importance_type='gain')\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': list(importance.keys()),\n",
        "    'Importance': list(importance.values())\n",
        "}).sort_values('Importance', ascending=False)\n",
        "\n",
        "print(\"\\n Top 10 Most Important Features:\")\n",
        "print(importance_df.head(10).to_string(index=False))\n"
      ],
      "metadata": {
        "id": "PFHBckssi-GQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tR50Z6qcjAb4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}