{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQ7QkU5KfxC2"
      },
      "outputs": [],
      "source": [
        "# ==============================\n",
        "# 4. Standardize the features\n",
        "# ==============================\n",
        "scaler = StandardScaler()\n",
        "data_scaled = pd.DataFrame(scaler.fit_transform(data_imputed), columns=data_imputed.columns)\n",
        "\n",
        "# ==============================\n",
        "# 5. Feature/target split\n",
        "# ==============================\n",
        "X = data_scaled.drop('WQI', axis=1)\n",
        "y = data_scaled['WQI']\n",
        "\n",
        "# Split into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# ==============================\n",
        "# 6. Train Linear Regression Model\n",
        "# ==============================\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# ==============================\n",
        "# 7. Predictions and Evaluation\n",
        "# ==============================\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"=== Linear Regression Model Evaluation ===\")\n",
        "print(f\"MAE:  {mae:.4f}\")\n",
        "print(f\"RMSE: {rmse:.4f}\")\n",
        "print(f\"R²:   {r2:.4f}\")\n",
        "\n",
        "# ==============================\n",
        "# 8. Actual vs Predicted Plot\n",
        "# ==============================\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.scatterplot(x=y_test, y=y_pred, alpha=0.7)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
        "plt.xlabel(\"Actual WQI\")\n",
        "plt.ylabel(\"Predicted WQI\")\n",
        "plt.title(\"Actual vs Predicted WQI\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ==============================\n",
        "# 9. Coefficients Overview\n",
        "# ==============================\n",
        "coefficients = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Coefficient': model.coef_\n",
        "}).sort_values(by='Coefficient', ascending=False)\n",
        "\n",
        "print(\"\\n=== Linear Regression Coefficients ===\")\n",
        "print(coefficients)\n",
        "\n",
        "# ==============================\n",
        "# 10. Residuals Distribution\n",
        "# ==============================\n",
        "residuals = y_test - y_pred\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.histplot(residuals, kde=True, bins=20)\n",
        "plt.xlabel(\"Residuals\")\n",
        "plt.title(\"Distribution of Residuals\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ==============================\n",
        "# 11. Cross-Validation\n",
        "# ==============================\n",
        "cv_scores = cross_val_score(model, X, y, cv=5, scoring='r2')\n",
        "print(f\"\\nCross-Validated R² Score: {np.mean(cv_scores):.4f} (±{np.std(cv_scores):.4f})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# 1. Train Random Forest Regressor\n",
        "# ==============================\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# ==============================\n",
        "# 2. Predictions and Evaluation\n",
        "# ==============================\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "\n",
        "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
        "rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
        "r2_rf = r2_score(y_test, y_pred_rf)\n",
        "\n",
        "print(\"\\n=== Random Forest Regression Performance ===\")\n",
        "print(f\"MAE :  {mae_rf:.4f}\")\n",
        "print(f\"RMSE:  {rmse_rf:.4f}\")\n",
        "print(f\"R²   :  {r2_rf:.4f}\")\n",
        "\n",
        "# ==============================\n",
        "# 3. Cross-Validation\n",
        "# ==============================\n",
        "cv_scores_rf = cross_val_score(rf_model, X, y, cv=5, scoring='r2')\n",
        "print(f\"\\nCross-Validated R² Score: {np.mean(cv_scores_rf):.4f} (±{np.std(cv_scores_rf):.4f})\")\n",
        "\n",
        "# ==============================\n",
        "# 4. Feature Importance\n",
        "# ==============================\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Importance': rf_model.feature_importances_\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "print(\"\\n=== Feature Importances ===\")\n",
        "print(importance_df)\n",
        "\n",
        "# ==============================\n",
        "# 5. Plot Feature Importance\n",
        "# ==============================\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Importance', y='Feature', data=importance_df, palette='viridis')\n",
        "plt.title('Feature Importance - Random Forest Regressor', fontsize=14)\n",
        "plt.xlabel('Relative Importance', fontsize=12)\n",
        "plt.ylabel('Feature', fontsize=12)\n",
        "plt.grid(axis='x', linestyle='--', alpha=0.6)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "8S9YkJscf6q2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using only Conductivity column as feature and WQI as target\n",
        "X_single = data_scaled[['Conductivity (mho/ Cm)']]\n",
        "y_single = data_scaled['WQI']\n",
        "\n",
        "# Split into Train and Test sets\n",
        "X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(X_single, y_single, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define model\n",
        "rf_single = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_single.fit(X_train_s, y_train_s)\n",
        "\n",
        "# Prediction and evaluation\n",
        "y_pred_s = rf_single.predict(X_test_s)\n",
        "mae_s = mean_absolute_error(y_test_s, y_pred_s)\n",
        "rmse_s = np.sqrt(mean_squared_error(y_test_s, y_pred_s))\n",
        "r2_s = r2_score(y_test_s, y_pred_s)\n",
        "\n",
        "print(\"\\n\\033[1;33m=== Random Forest Evaluation (Conductivity only) ===\\033[0m\")\n",
        "print(f\"MAE:  {mae_s:.4f}\")\n",
        "print(f\"RMSE: {rmse_s:.4f}\")\n",
        "print(f\"R2:   {r2_s:.4f}\")\n",
        "\n",
        "# Cross-validation\n",
        "cv_scores_s = cross_val_score(rf_single, X_single, y_single, cv=5, scoring='r2')\n",
        "print(f\"\\nR2-Score with Cross-Validation: {np.mean(cv_scores_s):.4f} (±{np.std(cv_scores_s):.4f})\")"
      ],
      "metadata": {
        "id": "_QCUgzivf7i6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Defining the model\n",
        "rf_model = RandomForestRegressor(random_state=42)\n",
        "\n",
        "# 2. Optimized hyperparameters\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'max_features': ['sqrt', 'log2']\n",
        "}\n",
        "\n",
        "# 3. Setting up GridSearchCV\n",
        "grid_search_rf = GridSearchCV(\n",
        "    estimator=rf_model,\n",
        "    param_grid=param_grid_rf,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    cv=5,\n",
        "    n_jobs=-1,  # Using all CPU cores\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# 4. Running the hyperparameter search\n",
        "print(\"Starting hyperparameter tuning...\")\n",
        "start_time = time.time()\n",
        "grid_search_rf.fit(X_train, y_train)\n",
        "print(f\"Execution time: {(time.time() - start_time)/60:.2f} minutes\")\n",
        "\n",
        "# 5. Results\n",
        "print(\"\\nBest parameters:\")\n",
        "print(grid_search_rf.best_params_)\n",
        "\n",
        "print(\"\\nBest score (MSE):\")\n",
        "print(f\"{grid_search_rf.best_score_:.4f}\")\n",
        "\n",
        "# 6. Saving the best model\n",
        "best_rf = grid_search_rf.best_estimator_\n"
      ],
      "metadata": {
        "id": "H1QdPluAf-eR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# 1. Define base XGBoost model\n",
        "xgb_model = XGBRegressor(\n",
        "    random_state=42,\n",
        "    objective='reg:squarederror',\n",
        "    n_jobs=-1,\n",
        "    verbosity=0  # Suppress internal XGBoost messages\n",
        ")\n",
        "\n",
        "# 2. Define parameter grid for hyperparameter tuning\n",
        "param_grid_xgb = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'subsample': [0.6, 0.8, 1.0],\n",
        "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
        "    'gamma': [0, 0.1, 0.2]\n",
        "}\n",
        "\n",
        "# 3. Setup advanced GridSearchCV with multiple scoring metrics\n",
        "grid_search_xgb = GridSearchCV(\n",
        "    estimator=xgb_model,\n",
        "    param_grid=param_grid_xgb,\n",
        "    scoring={\n",
        "        'MAE': 'neg_mean_absolute_error',\n",
        "        'MSE': 'neg_mean_squared_error',\n",
        "        'R2': 'r2'\n",
        "    },\n",
        "    refit='MSE',  # Select best model based on MSE\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        "    verbose=0  # Suppress cross-validation output\n",
        ")\n",
        "\n",
        "# 4. Run the search with time tracking\n",
        "print(\" Starting hyperparameter optimization...\")\n",
        "start_time = time.time()\n",
        "grid_search_xgb.fit(X_train, y_train)\n",
        "elapsed_time = (time.time() - start_time) / 60\n",
        "print(f\" Optimization completed in {elapsed_time:.2f} minutes.\")\n",
        "\n",
        "# 5. Show the final results\n",
        "print(\"\\n🎯 Best Hyperparameters:\")\n",
        "print(grid_search_xgb.best_params_)\n",
        "\n",
        "# Extract best index and performance metrics\n",
        "best_index = grid_search_xgb.best_index_\n",
        "results = pd.DataFrame(grid_search_xgb.cv_results_)\n",
        "\n",
        "print(\"\\n Best Model Evaluation Metrics:\")\n",
        "print(results.loc[best_index, [\n",
        "    'mean_test_MAE',\n",
        "    'mean_test_MSE',\n",
        "    'mean_test_R2'\n",
        "]].rename({\n",
        "    'mean_test_MAE': 'MAE',\n",
        "    'mean_test_MSE': 'MSE',\n",
        "    'mean_test_R2': 'R²'\n",
        "}).to_string())\n",
        "\n",
        "# 6. Save the best model to file\n",
        "best_xgb = grid_search_xgb.best_estimator_\n",
        "best_xgb.save_model('best_xgb_model.json')\n",
        "\n",
        "# 7. Analyze feature importance\n",
        "importance = best_xgb.get_booster().get_score(importance_type='gain')\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': list(importance.keys()),\n",
        "    'Importance': list(importance.values())\n",
        "}).sort_values('Importance', ascending=False)\n",
        "\n",
        "print(\"\\n Top 10 Most Important Features:\")\n",
        "print(importance_df.head(10).to_string(index=False))\n"
      ],
      "metadata": {
        "id": "u9Rk0vF9gIfx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}